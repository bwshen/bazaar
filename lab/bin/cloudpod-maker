#!/bin/bash -e
# This script must be executed from an SDMAIN_ROOT directory with compiled
# code, e.g. from the root of an unpacked tarball.
#
# A typical invocation from Jenkins would look like this:
#    ~/sdmain/src/scripts/jenkins/jenkins_rktool.py \
#        --set_build_display_name ${BUILD_URL} \
#                                 ${RESERVED_RESOURCE}-${BUILD_NUMBER}
#    ~/sdmain/lab/launcher/tarball_util.py --job_name Build_3.0 --build_num 315
#    RKRELEASE=`ls | grep 'rubrik-' | grep -v 'tar.gz'`
#    cd $RKRELEASE
#    export LOG_LEVEL=DEBUG
#    ~/sdmain/lab/bin/awspod-maker ~/sdmain . ${RESERVED_RESOURCE}
# Where ${RESERVED_RESOURCE} is e.g. 'awspod1.yml'.
#
# TODO:
#  - Consider skipping deployment in 'cluster_bootstrap_tool.py', instead
#    ensuring the AMI and the CLUSTER_BOOTSTRAP_DIR are from the same version
#    at all times.
#  - Determine if cluster_bootstrap_tool is needed on, or even works on,
#    one-vnode clusters.
#  - Move RKTEST_YML environment variable into a command line option of
#    'cluster_bootstrap_tool.py'.
#  - Determine if ANSIBLE_*, SKIP_CHECK_PROTECTED_VMS, etc are unused
#    or unnecessary and can be removed.
#  - See also TODO in 'dynapod-maker'.
#
# This script was originally copied pretty much "as is" from the
# 'dynapod-maker' script, which was, in turn, copied from the
# 'recover-dyna-pod' job.  No effort was made to clean it up at the time.
#

usage() {
    echo "Usage: $0 <reserved-resource>"
    echo "   or: $0 <infra-sdmain-dir> <cluster-bootstrap-dir> "\
                   "<cloud-provider> <reserved-resource>"
}

set -x # Enable bash logging of each line in the script as it is run

INFRA_SDMAIN_DIR="."
CLUSTER_BOOTSTRAP_DIR="."
if [ $# -eq 4 ]; then
    INFRA_SDMAIN_DIR="$1"
    CLUSTER_BOOTSTRAP_DIR="$2"
    CLOUD_PROVIDER="$3"
    shift 3
fi

if [ $# -ne 1 ]; then
    usage
    exit 1
fi

export RESERVED_RESOURCE=$1
export ANSIBLE_LOG_PATH="./ansible.log.txt"
export ANSIBLE_HOST_KEY_CHECKING=False
export LOG_LEVEL=DEBUG

# For example: RESERVED_RESOURCE=awspod1.yml, podname=awspod1,
#              specs_yml=awspod1.specs.yml
podname=${RESERVED_RESOURCE%%.*}
specs_yml=`echo "$RESERVED_RESOURCE" | \
    sed -re 's/^(.+)\.([^\.]+)$/\1.specs.\2/'`

###############################################################################

# Create AWS Pod
LOG_FILE="./cloud_podmaker.log.txt" \
    ${INFRA_SDMAIN_DIR}/src/py/utils/cloud_podmaker.py \
        --spec_file_path "${INFRA_SDMAIN_DIR}/conf/${specs_yml}" \
        --out_dir "${CLUSTER_BOOTSTRAP_DIR}" \
        --remove_existing \
        --cloud_provider "${CLOUD_PROVIDER}"

echo  "Bootstrapping cluster using cluster_bootstrap_tool.py..."
export RKTEST_YML=conf/${RESERVED_RESOURCE}
export SKIP_CHECK_PROTECTED_VMS=1
${CLUSTER_BOOTSTRAP_DIR}/src/scripts/tests/cluster_bootstrap_tool.py \
    --skip_stats_audit

###############################################################################

# Stage the yaml and jinja files we generated into the outer directory, which
# in the case of a Jenkins job is the top level of the workspace directory
# where artifacts will ultimately be collected for publishing.
cp -vt .. \
   ${CLUSTER_BOOTSTRAP_DIR}/conf/${RESERVED_RESOURCE} \
   ${CLUSTER_BOOTSTRAP_DIR}/deployment/ansible/*${CLOUD_PROVIDER}pod* *.txt

if [[ -v BUILD_NUMBER && -v JOB_NAME && -v BUILD_URL ]]; then
    echo "Cloud pod resources generated by ${JOB_NAME} number ${BUILD_NUMBER}" \
         "at ${BUILD_URL}" > ../${podname}.txt
fi

# Upload all the awspod files to the FTP server
${INFRA_SDMAIN_DIR}/src/py/utils/ftp_util.py \
  --ftp_server "files-master.colo.rubrik-lab.com" \
  --ftp_user "ubuntu" \
  --ftp_password "qwerty" \
  --make_directory "Dynapod/${podname}" \
  --upload_file ../*${CLOUD_PROVIDER}pod* ../*.txt \
  --destination "Dynapod/${podname}/"
